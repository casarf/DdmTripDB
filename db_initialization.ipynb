{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MongoDB \n",
    " \n",
    " In this notebook you will see how to use Python to communicate with MongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HOST='localhost'\n",
    "PORT='27017'\n",
    "MONGO_URL = 'mongodb://{}:{}'.format(HOST, PORT)\n",
    "DB_NAME = 'TripAdvisor'\n",
    "COLLECTION_NAME = 'EuropeanRestaurants'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGO_URL)\n",
    "db = client[DB_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('./parser/tripadvisor_european_restaurants.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_result = db[COLLECTION_NAME].insert_many(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query by MongoDB id\n",
    "\n",
    "Select the restaurant saved with the given MongoDB id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6544c90a528652e1cc0137ce'),\n",
       " 'restaurant_link': 'g1005749-d4414073',\n",
       " 'restaurant_name': 'La terrasse',\n",
       " 'location': {'country': 'France',\n",
       "  'region': \"Provence-Alpes-Cote d'Azur\",\n",
       "  'province': 'Var',\n",
       "  'city': 'Rocbaron',\n",
       "  'address': '10 rue des Faysonnes, 83136 Rocbaron France',\n",
       "  'latitude': 43.30408,\n",
       "  'longitude': 6.09149},\n",
       " 'claimed': False,\n",
       " 'awards': ['Certificate of Excellence 2018',\n",
       "  'Certificate of Excellence 2017'],\n",
       " 'popularity_detailed': '#4 of 10 Restaurants in Rocbaron',\n",
       " 'popularity_generic': '#4 of 12 places to eat in Rocbaron',\n",
       " 'top_tags': ['Mid-range', 'Italian', 'French', 'Pizza'],\n",
       " 'price_level': ['€€', '€€€'],\n",
       " 'price_range': [],\n",
       " 'food_specification': {'cuisines': ['French', 'Pizza', 'Italian'],\n",
       "  'special_diets': [],\n",
       "  'vegetarian_friendly': False,\n",
       "  'vegan_options': False,\n",
       "  'gluten_free': False},\n",
       " 'availability': {'meals': ['Lunch', 'Dinner'],\n",
       "  'features': ['Takeout',\n",
       "   'Reservations',\n",
       "   'Outdoor Seating',\n",
       "   'Seating',\n",
       "   'Serves Alcohol',\n",
       "   'Table Service',\n",
       "   'Wheelchair Accessible'],\n",
       "  'original_open_hours': '',\n",
       "  'open_days_per_week': '',\n",
       "  'open_hours_per_week': '',\n",
       "  'working_shifts_per_week': ''},\n",
       " 'rating': {'avg_rating': '4.0',\n",
       "  'total_reviews_count': '79.0',\n",
       "  'default_language': 'All languages',\n",
       "  'reviews_count_in_default_language': '79.0',\n",
       "  'excellent': '36.0',\n",
       "  'very_good': '28.0',\n",
       "  'average': '10.0',\n",
       "  'poor': '4.0',\n",
       "  'terrible': '1.0',\n",
       "  'food': '4.5',\n",
       "  'service': '4.0',\n",
       "  'value': '4.5',\n",
       "  'atmosphere': ''},\n",
       " 'keywords': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bson.objectid import ObjectId\n",
    "db[COLLECTION_NAME].find_one({\"_id\":ObjectId(\"6544c90a528652e1cc0137ce\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by field value\n",
    "\n",
    "Select all the English tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.cursor.Cursor at 0x1050d92d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[COLLECTION_NAME].find({\"lang\":\"en\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mongo returns are cursors over the result set, so we need to parse it to retrieve the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put :100 to limit the results\n",
    "list(db[COLLECTION_NAME].find({\"lang\":\"en\"})[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very inefficient, as it loads all the data into an array. However, for sake of time we will use the previous way thorough the notebook\n",
    "\n",
    "The correct way is to iterate over it. \n",
    "\n",
    "In the next cell we will print the first **5** tweets returned by the previous query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in db[COLLECTION_NAME].find({\"lang\":\"en\"})[:5]: \n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = db[COLLECTION_NAME].find({\"lang\":\"en\"})[:10]\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query using **comparison** operators\n",
    "\n",
    "Retrieve the first 100 tweets posted during March 2018\n",
    "\n",
    "You can use the `[:N]` notation as shortcut to define **limits** in the MongoDB query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "query = {\n",
    "    \"date\":{\n",
    "    \"$gte\":datetime.strptime(\"2018-03-01T00:00:00\",\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    \"$lt\":datetime.strptime(\"2018-04-01T00:00:00\",\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    }\n",
    "}\n",
    "\n",
    "result = db[COLLECTION_NAME].find(query)[:100]\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the first 100 **non-English** tweets posted during March 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"date\":{\n",
    "    \"$gte\":datetime.strptime(\"2018-03-01T00:00:00\",\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    \"$lt\":datetime.strptime(\"2018-04-01T00:00:00\",\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    },\n",
    "    \"lang\":{\n",
    "        \"$ne\":\"en\"\n",
    "    }\n",
    "}\n",
    "result = db[COLLECTION_NAME].find(query)[:100]\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all the tweets that are **not** originating from the United States\n",
    "\n",
    "You can query the embedded fields by using the dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"place.country_code\":{\n",
    "        \"$ne\":\"US\"\n",
    "    }\n",
    "}\n",
    "\n",
    "result = db[COLLECTION_NAME].find(query)[:100]\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the tweets that include at least one link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"entities.urls.1\":{\n",
    "        \"$exists\":True\n",
    "    }\n",
    "}\n",
    "\n",
    "result = db[COLLECTION_NAME].find(query)[:100]\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mongo allows also to filter the fields you want to retrieve.\n",
    "Now, let's repeat the previous query but keep only the text of the tweet, the date and the location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"place.country_code\":{\n",
    "        \"$ne\":\"US\"\n",
    "    }\n",
    "}\n",
    "\n",
    "fields = {\n",
    "    \"text\":1,\n",
    "    \"date\":1,\n",
    "    \"place.name\":1\n",
    "}\n",
    "\n",
    "result = db[COLLECTION_NAME].find(query,fields)[:100]\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert a new document in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here give a unique name to your collection\n",
    "WRITE_COLLECTION_NAME = \"my_tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweet = {\n",
    "        'created_at': 'Fri Jul 31 15:16:13 +0000 2020',\n",
    "        'id': 1289218313222905860,\n",
    "        'id_str': '1289218313222905860',\n",
    "        'text': 'Nasce FABRE, il Consorzio per la valutazione della sicurezza e il monitoraggio di ponti e viadotti in Italia, volut… https://t.co/BvIs79y61y',\n",
    "        'truncated': True,\n",
    "        'entities': {\n",
    "            'hashtags': [],\n",
    "            'symbols': [],\n",
    "            'user_mentions': [],\n",
    "            'urls': [{\n",
    "                'url': 'https://t.co/BvIs79y61y',\n",
    "                'expanded_url': 'https://twitter.com/i/web/status/1289218313222905860',\n",
    "                'display_url': 'twitter.com/i/web/status/1…',\n",
    "                'indices': [117, 140]\n",
    "            }]\n",
    "        },\n",
    "        'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
    "        'in_reply_to_status_id': None,\n",
    "        'in_reply_to_status_id_str': None,\n",
    "        'in_reply_to_user_id': None,\n",
    "        'in_reply_to_user_id_str': None,\n",
    "        'in_reply_to_screen_name': None,\n",
    "        'geo': None,\n",
    "        'coordinates': None,\n",
    "        'place': None,\n",
    "        'contributors': None,\n",
    "        'is_quote_status': False,\n",
    "        'retweet_count': 4,\n",
    "        'favorite_count': 26,\n",
    "        'favorited': False,\n",
    "        'retweeted': False,\n",
    "        'possibly_sensitive': False,\n",
    "        'lang': 'it'\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_result = db[WRITE_COLLECTION_NAME].insert_one(new_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the **Id** of the inserted document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_result.inserted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mongo does not care about the schema. So you can insert incomplete tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_tweet = {\n",
    "    \"text\":\"Dummy tweet\",\n",
    "    'created_at': 'Fri Jul 31 15:13:13 +0000 2020',\n",
    "    'id': 1289218313222905860,\n",
    "    \"truncated\":False,\n",
    "    'lang': 'it'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[WRITE_COLLECTION_NAME].insert_one(incomplete_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update\n",
    "\n",
    "An update is mongo is composed by a query - as in the find operator - and the actual update. The query is used to select which documents you want to modify, like a WHERE clause in SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a boolean field **spam** and set it to true if a tweet text is not in english, is shorter than 20 characters and it wasn't truncated (i.e., the actual text is longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"$expr\": { \"$lte\": [ { \"$strLenCP\": \"$text\" }, 20 ] },\n",
    "    \"truncated\":False,\n",
    "    \"lang\":{\n",
    "        \"$ne\":\"en\"\n",
    "    }\n",
    "}\n",
    "\n",
    "update = {\n",
    "    \"$set\":{\n",
    "        \"spam\":True\n",
    "    }\n",
    "}\n",
    "\n",
    "results = db[WRITE_COLLECTION_NAME].update_many(query,update)\n",
    "\n",
    "print(results.matched_count, \"tweets matched the query\")\n",
    "print(results.modified_count, \"tweets were modified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"spam\":True\n",
    "}\n",
    "\n",
    "result = db[WRITE_COLLECTION_NAME].find(query)[:100]\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete\n",
    "\n",
    "The delete expects as input a query with the same format as a find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all the tweets with the information about the **user_id** missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1c2e459804c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWRITE_COLLECTION_NAME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleted_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "     \"user_id\":{\n",
    "         \"$exists\":False\n",
    "     }\n",
    "}\n",
    "\n",
    "result = db[WRITE_COLLECTION_NAME].delete_many(query)\n",
    "\n",
    "result.deleted_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the top 10 tweeting users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [{\n",
    "    \"$group\":{\n",
    "        \"_id\":\"$user_id\",\n",
    "        \"tweet_number\":{\n",
    "            \"$sum\":1\n",
    "        }\n",
    "    }\n",
    "},{\n",
    "    \"$sort\":{\n",
    "        \"tweet_number\":-1\n",
    "    }\n",
    "},{\n",
    "    \"$limit\":10\n",
    "}]\n",
    "\n",
    "result = db[COLLECTION_NAME].aggregate(pipeline)\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top 10 most used hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [{\n",
    "    \"$match\":{\n",
    "        \"entities.hashtags.1\":\n",
    "        {\n",
    "            \"$exists\":True\n",
    "        }\n",
    "    }\n",
    "},{\n",
    "    \"$project\":{\n",
    "        \"hashtag\":\"$entities.hashtags.text\"\n",
    "    }\n",
    "},{\n",
    "    \"$unwind\":\"$hashtag\"\n",
    "},{\n",
    "    \"$group\":{\n",
    "        \"_id\":\"$hashtag\",\n",
    "        \"count\":{\n",
    "            \"$sum\":1\n",
    "        }\n",
    "    }\n",
    "},{\n",
    "    \"$sort\":{\n",
    "        \"count\":-1\n",
    "    }\n",
    "},{\n",
    "    \"$limit\":10\n",
    "}]\n",
    "\n",
    "result = db[COLLECTION_NAME].aggregate(pipeline)\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup (aka Join)\n",
    "\n",
    "Other information about the users is stored in the **user** collection. In order to combine it with the information in the **tweet** collection we need to join them.\n",
    "\n",
    "Retrieve where the most active user are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [{\n",
    "    \"$group\":{\n",
    "        \"_id\":\"$user_id\",\n",
    "        \"tweet_number\":{\n",
    "            \"$sum\":1\n",
    "        }\n",
    "    }\n",
    "},{\n",
    "    \"$lookup\":{\n",
    "        \"from\":\"user\",\n",
    "        \"localField\":\"_id\",\n",
    "        \"foreignField\":\"_id\",\n",
    "        \"as\":\"popular_locations\"\n",
    "    }\n",
    "},{\n",
    "    \"$unwind\":\"$popular_locations\"\n",
    "},{\n",
    "    \"$project\":{\n",
    "        \"location\":\"$popular_locations.location\",\n",
    "        \"tweet_number\":1\n",
    "    }\n",
    "},{\n",
    "    \"$match\":{\n",
    "        \"location\":{\n",
    "            \"$ne\":None\n",
    "        }\n",
    "    }\n",
    "},{\n",
    "    \"$group\":{\n",
    "        \"_id\":\"$location\",\n",
    "        \"tweets\":{\n",
    "            \"$sum\":\"$tweet_number\"\n",
    "        },\n",
    "        \"unique_users\":{\n",
    "            \"$sum\":1\n",
    "        }\n",
    "    }\n",
    "},{\n",
    "    \"$sort\":{\n",
    "        \"tweets\":-1\n",
    "    }\n",
    "}]\n",
    "\n",
    "result = db[COLLECTION_NAME].aggregate(pipeline)\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
